{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "950690b7-6798-4145-b6e0-4216a0532890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path ./Faces exists and is accessible.\n",
      "Files found in the directory:\n",
      "Jim_Carrey.jpg\n",
      "Jim_Carrey2.jpg\n",
      "Jim_Carrey1.jpg\n",
      "Viktoriia_Drozdovska2.jpg\n",
      "Viktoriia_Drozdovska1.jpg\n",
      "Viktoriia_Drozdovska.jpg\n",
      "Kim_Kardashian.jpg\n",
      "Kim_Kardashian2.jpg\n",
      "Kim_Kardashian1.jpg\n",
      "Kim_Kardashian-checkpoint.jpg\n",
      "Total number of images: 9\n",
      "Unique person names: {'Viktoriia', 'Jim', 'Kim'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Define the correct path based on your folder structure\n",
    "path = './Faces'  # Change this to the exact path where the image files are located\n",
    "\n",
    "# Check if the folder exists to avoid errors\n",
    "if not os.path.exists(path):\n",
    "    print(f\"Path {path} does not exist. Please verify the path.\")\n",
    "else:\n",
    "    print(f\"Path {path} exists and is accessible.\")\n",
    "\n",
    "# Debug: Print all files in the directory to see if images are present\n",
    "print(\"Files found in the directory:\")\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        print(file)  # Print each file name found\n",
    "\n",
    "# Initialize the lists to store image paths and person names\n",
    "image_path_names = []\n",
    "person_names = set()\n",
    "\n",
    "# Adjust the glob pattern to match your image file names, including subfolders\n",
    "for file_name in glob.glob(os.path.join(path, '**', '*.jpg'), recursive=True):\n",
    "    image_path_names.append(file_name)\n",
    "    # Extract the person name by splitting the filename\n",
    "    person_names.add(os.path.basename(file_name).split('_')[0])\n",
    "\n",
    "# Check the results\n",
    "print(f\"Total number of images: {len(image_path_names)}\")  # Should print the total number of images\n",
    "print(f\"Unique person names: {person_names}\")  # Should print the unique person names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1ab3783-fdc6-4bc1-9e19-cc82906d7fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file 'mmod_human_face_detector.dat.bz2' downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "# Step 1: Download the Dlib CNN face detector model using Python's urllib\n",
    "model_url = \"http://dlib.net/files/mmod_human_face_detector.dat.bz2\"\n",
    "model_file = \"mmod_human_face_detector.dat.bz2\"\n",
    "\n",
    "# Download the file and save it locally\n",
    "urllib.request.urlretrieve(model_url, model_file)\n",
    "print(f\"Model file '{model_file}' downloaded successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6de2eba-0ed0-4985-9ae2-4250e609e2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Either 'mmod_human_face_detector.dat.bz2' is missing or 'mmod_human_face_detector.dat' already exists.\n"
     ]
    }
   ],
   "source": [
    "import bz2\n",
    "import shutil\n",
    "\n",
    "# Step 2: Decompress the .bz2 file to get the .dat file\n",
    "compressed_file = \"mmod_human_face_detector.dat.bz2\"\n",
    "extracted_file = \"mmod_human_face_detector.dat\"\n",
    "\n",
    "# Decompress the file if it exists\n",
    "if not os.path.exists(extracted_file) and os.path.exists(compressed_file):\n",
    "    with bz2.BZ2File(compressed_file, 'rb') as file, open(extracted_file, 'wb') as output:\n",
    "        shutil.copyfileobj(file, output)\n",
    "    print(f\"Decompressed '{compressed_file}' to '{extracted_file}'.\")\n",
    "else:\n",
    "    print(f\"Either '{compressed_file}' is missing or '{extracted_file}' already exists.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1f95bbe-a9b9-475e-a4ff-487e289e862e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dlib\n",
      "  Using cached dlib-19.24.6-cp312-cp312-macosx_14_0_universal2.whl\n",
      "Collecting opencv-python-headless\n",
      "  Using cached opencv_python_headless-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (3.8.4)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/anaconda3/lib/python3.12/site-packages (from opencv-python-headless) (1.26.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Using cached opencv_python_headless-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl (54.8 MB)\n",
      "Installing collected packages: dlib, opencv-python-headless\n",
      "Successfully installed dlib-19.24.6 opencv-python-headless-4.10.0.84\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Install necessary libraries using %pip in Jupyter\n",
    "%pip install dlib opencv-python-headless matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1e399e0-bd33-4a5d-b754-db4cf0e2b834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dlib CNN face detector model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load the Dlib CNN face detector model\n",
    "model_file = \"mmod_human_face_detector.dat\"\n",
    "\n",
    "# Check if the model file exists before loading\n",
    "if os.path.exists(model_file):\n",
    "    dnnFaceDetector = dlib.cnn_face_detection_model_v1(model_file)\n",
    "    print(\"Dlib CNN face detector model loaded successfully.\")\n",
    "else:\n",
    "    print(f\"Model file '{model_file}' not found. Please ensure it was extracted successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "508cb7ed-ca0c-49db-b503-d89ef32cb159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path /Users/viktoriiadrozdovska/face_rec_images exists and is accessible.\n",
      "Files and directories found in 'face_rec_images':\n",
      "Directory: face_rec_images\n",
      "Directory: .ipynb_checkpoints\n",
      "Directory: Faces\n",
      "File: facerec.ipynb\n",
      "File: mmod_human_face_detector.dat\n",
      "File: mmod_human_face_detector.dat.bz2\n",
      "Directory: .ipynb_checkpoints\n",
      "File: facerec-checkpoint.ipynb\n",
      "Directory: Jim_Carrey\n",
      "Directory: Viktoriia Drozdovska\n",
      "Directory: .ipynb_checkpoints\n",
      "Directory: Kim_Kardashian\n",
      "Directory: .ipynb_checkpoints\n",
      "File: Jim_Carrey.jpg\n",
      "File: Jim_Carrey2.jpg\n",
      "File: Jim_Carrey1.jpg\n",
      "File: Viktoriia_Drozdovska2.jpg\n",
      "File: Viktoriia_Drozdovska1.jpg\n",
      "File: Viktoriia_Drozdovska.jpg\n",
      "Directory: .ipynb_checkpoints\n",
      "File: Kim_Kardashian.jpg\n",
      "File: Kim_Kardashian2.jpg\n",
      "File: Kim_Kardashian1.jpg\n",
      "File: Kim_Kardashian-checkpoint.jpg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import glob\n",
    "\n",
    "# Define the path to the `face_rec_images` folder\n",
    "path = '/Users/viktoriiadrozdovska/face_rec_images'  # The path to the main directory containing the Faces folder\n",
    "\n",
    "# Check if the folder exists to avoid errors\n",
    "if not os.path.exists(path):\n",
    "    print(f\"Path {path} does not exist. Please verify the path.\")\n",
    "else:\n",
    "    print(f\"Path {path} exists and is accessible.\")\n",
    "\n",
    "# Debug: Print all files and folders in the directory to see if images or subfolders are present\n",
    "print(\"Files and directories found in 'face_rec_images':\")\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for name in dirs:\n",
    "        print(f\"Directory: {name}\")\n",
    "    for name in files:\n",
    "        print(f\"File: {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e425ea86-098e-4e40-b512-2bf019cc924a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e8250d5-a077-420f-9514-8903ca9b015e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Images Path: /Users/viktoriiadrozdovska/face_rec_images/Faces\n",
      "Cropped Images Path: /Users/viktoriiadrozdovska/face_rec_images/Images_crop\n"
     ]
    }
   ],
   "source": [
    "input_images_path = os.path.join(path, 'Faces')  # Folder containing input images (e.g., Person1.jpg, Person2.jpg)\n",
    "cropped_images_path = os.path.join(path, 'Images_crop')  # Folder to save cropped images\n",
    "\n",
    "# Create the 'Images_crop' directory if it doesn't exist\n",
    "os.makedirs(cropped_images_path, exist_ok=True)\n",
    "\n",
    "# Verify paths\n",
    "print(f\"Input Images Path: {input_images_path}\")\n",
    "print(f\"Cropped Images Path: {cropped_images_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49a5aa29-282f-44a0-b97c-53a6f765b52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images found: 0\n",
      "Images found for processing: []\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all images in the input folder\n",
    "image_files = [f for f in os.listdir(input_images_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Check the number of images to be processed\n",
    "print(f\"Number of images found: {len(image_files)}\")\n",
    "\n",
    "# Display the image file names\n",
    "print(\"Images found for processing:\", image_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2191b310-9ef6-486a-a1cb-3427778e32be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (2.32.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2024.8.30)\n",
      "Using cached opencv_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl (54.8 MB)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.10.0.84\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python numpy requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64e565e5-ec31-45a4-ad05-656ae11bf51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Haar Cascade classifier from https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml...\n",
      "Downloaded Haar Cascade classifier and saved to '/Users/viktoriiadrozdovska/face_rec_images/Images_crop/haarcascade_frontalface_default.xml'.\n",
      "Haar Cascade face detector initialized successfully.\n",
      "Cropped face saved for 'Jim_Carrey.jpg' at '/Users/viktoriiadrozdovska/face_rec_images/Images_crop/Jim_Carrey/Jim_Carrey_cropped.jpg'.\n",
      "Cropped face saved for 'Jim_Carrey2.jpg' at '/Users/viktoriiadrozdovska/face_rec_images/Images_crop/Jim_Carrey/Jim_Carrey2_cropped.jpg'.\n",
      "Cropped face saved for 'Jim_Carrey1.jpg' at '/Users/viktoriiadrozdovska/face_rec_images/Images_crop/Jim_Carrey/Jim_Carrey1_cropped.jpg'.\n",
      "Cropped face saved for 'Viktoriia_Drozdovska2.jpg' at '/Users/viktoriiadrozdovska/face_rec_images/Images_crop/Viktoriia Drozdovska/Viktoriia_Drozdovska2_cropped.jpg'.\n",
      "Cropped face saved for 'Viktoriia_Drozdovska1.jpg' at '/Users/viktoriiadrozdovska/face_rec_images/Images_crop/Viktoriia Drozdovska/Viktoriia_Drozdovska1_cropped.jpg'.\n",
      "Cropped face saved for 'Viktoriia_Drozdovska.jpg' at '/Users/viktoriiadrozdovska/face_rec_images/Images_crop/Viktoriia Drozdovska/Viktoriia_Drozdovska_cropped.jpg'.\n",
      "Cropped face saved for 'Kim_Kardashian.jpg' at '/Users/viktoriiadrozdovska/face_rec_images/Images_crop/Kim_Kardashian/Kim_Kardashian_cropped.jpg'.\n",
      "Cropped face saved for 'Kim_Kardashian2.jpg' at '/Users/viktoriiadrozdovska/face_rec_images/Images_crop/Kim_Kardashian/Kim_Kardashian2_cropped.jpg'.\n",
      "Cropped face saved for 'Kim_Kardashian1.jpg' at '/Users/viktoriiadrozdovska/face_rec_images/Images_crop/Kim_Kardashian/Kim_Kardashian1_cropped.jpg'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "# Define Paths\n",
    "input_images_path = '/Users/viktoriiadrozdovska/face_rec_images/Faces'\n",
    "cropped_images_path = '/Users/viktoriiadrozdovska/face_rec_images/Images_crop'\n",
    "cascade_filename = 'haarcascade_frontalface_default.xml'\n",
    "cascade_url = 'https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml'\n",
    "cascade_path = os.path.join(cropped_images_path, cascade_filename)  # Save cascade in output directory\n",
    "\n",
    "def download_haar_cascade(url, save_path):\n",
    "    \"\"\"\n",
    "    Downloads the Haar Cascade XML file from the specified URL.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Downloading Haar Cascade classifier from {url}...\")\n",
    "        response = requests.get(url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            os.makedirs(os.path.dirname(save_path), exist_ok=True)  # Ensure the directory exists\n",
    "            with open(save_path, 'wb') as file:\n",
    "                for chunk in response.iter_content(chunk_size=1024):\n",
    "                    if chunk:\n",
    "                        file.write(chunk)\n",
    "            print(f\"Downloaded Haar Cascade classifier and saved to '{save_path}'.\")\n",
    "        else:\n",
    "            print(f\"Failed to download Haar Cascade classifier. Status code: {response.status_code}\")\n",
    "            exit(1)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while downloading Haar Cascade classifier: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "# Check if Haar Cascade file exists; if not, download it\n",
    "if not os.path.exists(cascade_path):\n",
    "    download_haar_cascade(cascade_url, cascade_path)\n",
    "else:\n",
    "    print(f\"Haar Cascade classifier found at '{cascade_path}'.\")\n",
    "\n",
    "# Initialize Haar Cascade face detector\n",
    "face_cascade = cv2.CascadeClassifier(cascade_path)\n",
    "if face_cascade.empty():\n",
    "    print(\"Error loading Haar Cascade classifier. Check the cascade_path.\")\n",
    "    exit(1)\n",
    "else:\n",
    "    print(\"Haar Cascade face detector initialized successfully.\")\n",
    "\n",
    "# Supported image extensions\n",
    "supported_extensions = ('.png', '.jpg', '.jpeg', '.bmp', '.tiff')\n",
    "\n",
    "# Iterate over each person's folder in the input directory\n",
    "for person_name in os.listdir(input_images_path):\n",
    "    person_dir = os.path.join(input_images_path, person_name)\n",
    "    if not os.path.isdir(person_dir):\n",
    "        continue  # Skip files, only process directories\n",
    "\n",
    "    # Iterate over each image for the person\n",
    "    for filename in os.listdir(person_dir):\n",
    "        if not filename.lower().endswith(supported_extensions):\n",
    "            continue  # Skip unsupported file formats\n",
    "\n",
    "        file_path = os.path.join(person_dir, filename)\n",
    "        img = cv2.imread(file_path)\n",
    "\n",
    "        if img is None:\n",
    "            print(f\"Failed to read '{file_path}'. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect faces\n",
    "        faces = face_cascade.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.8,\n",
    "            minNeighbors=6,\n",
    "            minSize=(60, 60)\n",
    "        )\n",
    "\n",
    "        if len(faces) == 1:\n",
    "            (x, y, w, h) = faces[0]\n",
    "            cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "            if cropped_face.size == 0:\n",
    "                print(f\"Invalid crop for '{file_path}'. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Create person's directory in cropped_images_path\n",
    "            person_cropped_dir = os.path.join(cropped_images_path, person_name)\n",
    "            os.makedirs(person_cropped_dir, exist_ok=True)\n",
    "\n",
    "            # Save the cropped face\n",
    "            cropped_filename = f\"{os.path.splitext(filename)[0]}_cropped.jpg\"\n",
    "            cropped_path = os.path.join(person_cropped_dir, cropped_filename)\n",
    "            success = cv2.imwrite(cropped_path, cropped_face)\n",
    "            if success:\n",
    "                print(f\"Cropped face saved for '{filename}' at '{cropped_path}'.\")\n",
    "            else:\n",
    "                print(f\"Failed to save cropped face for '{filename}'.\")\n",
    "        elif len(faces) > 1:\n",
    "            print(f\"Multiple faces detected in '{file_path}'. Skipping.\")\n",
    "        else:\n",
    "            print(f\"No face detected in '{file_path}'. Skipping.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ab80e3c-84ad-43d5-b0f5-60496d381e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person 'Jim_Carrey': 2 training and 1 testing images.\n",
      "Person 'Viktoriia Drozdovska': 2 training and 1 testing images.\n",
      "Person 'Kim_Kardashian': 2 training and 1 testing images.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Define Paths\n",
    "cropped_images_path = '/Users/viktoriiadrozdovska/face_rec_images/Images_crop'\n",
    "train_dir = '/Users/viktoriiadrozdovska/face_rec_images/train'\n",
    "test_dir = '/Users/viktoriiadrozdovska/face_rec_images/test'\n",
    "split_ratio = 0.8  # 80% training, 20% testing\n",
    "\n",
    "# Create train and test directories\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Iterate over each person's folder\n",
    "for person_name in os.listdir(cropped_images_path):\n",
    "    person_cropped_dir = os.path.join(cropped_images_path, person_name)\n",
    "    if not os.path.isdir(person_cropped_dir):\n",
    "        continue  # Skip if not a directory\n",
    "\n",
    "    images = [f for f in os.listdir(person_cropped_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]\n",
    "    random.shuffle(images)  # Shuffle to ensure randomness\n",
    "\n",
    "    split_index = int(len(images) * split_ratio)\n",
    "    train_images = images[:split_index]\n",
    "    test_images = images[split_index:]\n",
    "\n",
    "    # Create person's train and test directories\n",
    "    person_train_dir = os.path.join(train_dir, person_name)\n",
    "    person_test_dir = os.path.join(test_dir, person_name)\n",
    "    os.makedirs(person_train_dir, exist_ok=True)\n",
    "    os.makedirs(person_test_dir, exist_ok=True)\n",
    "\n",
    "    # Copy training images\n",
    "    for img in train_images:\n",
    "        src = os.path.join(person_cropped_dir, img)\n",
    "        dst = os.path.join(person_train_dir, img)\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    # Copy testing images\n",
    "    for img in test_images:\n",
    "        src = os.path.join(person_cropped_dir, img)\n",
    "        dst = os.path.join(person_test_dir, img)\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    print(f\"Person '{person_name}': {len(train_images)} training and {len(test_images)} testing images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dedb7bb0-e390-4381-9323-874a5c21ebfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting face_recognition\n",
      "  Using cached face_recognition-1.3.0-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
      "  Using cached face_recognition_models-0.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: Click>=6.0 in /opt/anaconda3/lib/python3.12/site-packages (from face_recognition) (8.1.7)\n",
      "Requirement already satisfied: dlib>=19.7 in /opt/anaconda3/lib/python3.12/site-packages (from face_recognition) (19.24.6)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from face_recognition) (1.26.4)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.12/site-packages (from face_recognition) (10.3.0)\n",
      "Using cached face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Installing collected packages: face-recognition-models, face_recognition\n",
      "Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install face_recognition\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86478ad4-d7ba-44c2-ae72-be7d392928f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face encodings saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import face_recognition\n",
    "import pickle\n",
    "\n",
    "# Paths\n",
    "train_dir = '/Users/viktoriiadrozdovska/face_rec_images/train'\n",
    "model_save_path = '/Users/viktoriiadrozdovska/face_rec_images/face_encodings.pkl'\n",
    "\n",
    "# Initialize lists\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "\n",
    "for person_name in os.listdir(train_dir):\n",
    "    person_train_dir = os.path.join(train_dir, person_name)\n",
    "    if not os.path.isdir(person_train_dir):\n",
    "        continue\n",
    "\n",
    "    for img_name in os.listdir(person_train_dir):\n",
    "        img_path = os.path.join(person_train_dir, img_name)\n",
    "        image = face_recognition.load_image_file(img_path)\n",
    "        encodings = face_recognition.face_encodings(image)\n",
    "\n",
    "        if len(encodings) == 0:\n",
    "            print(f\"No faces found in '{img_path}'. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        known_face_encodings.append(encodings[0])\n",
    "        known_face_names.append(person_name)\n",
    "\n",
    "# Save encodings to a file\n",
    "data = {\"encodings\": known_face_encodings, \"names\": known_face_names}\n",
    "with open(model_save_path, \"wb\") as f:\n",
    "    pickle.dump(data, f)\n",
    "\n",
    "print(\"Face encodings saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17397310-4742-4352-9ae0-59fac5a57896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "per_person_accuracy: {'Jim_Carrey': 100.0, 'Viktoriia Drozdovska': 100.0, 'Kim_Kardashian': 100.0}\n",
      "Type of per_person_accuracy: <class 'dict'>\n",
      "List of items: [('Jim_Carrey', 100.0), ('Viktoriia Drozdovska', 100.0), ('Kim_Kardashian', 100.0)]\n",
      "Type of list(per_person_accuracy.items()): <class 'list'>\n",
      "Item: ('Jim_Carrey', 100.0) Type: <class 'tuple'>\n",
      " - Element: Jim_Carrey Type: <class 'str'>\n",
      " - Element: 100.0 Type: <class 'float'>\n",
      "Item: ('Viktoriia Drozdovska', 100.0) Type: <class 'tuple'>\n",
      " - Element: Viktoriia Drozdovska Type: <class 'str'>\n",
      " - Element: 100.0 Type: <class 'float'>\n",
      "Item: ('Kim_Kardashian', 100.0) Type: <class 'tuple'>\n",
      " - Element: Kim_Kardashian Type: <class 'str'>\n",
      " - Element: 100.0 Type: <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "print(\"per_person_accuracy:\", per_person_accuracy)\n",
    "print(\"Type of per_person_accuracy:\", type(per_person_accuracy))\n",
    "print(\"List of items:\", list(per_person_accuracy.items()))\n",
    "print(\"Type of list(per_person_accuracy.items()):\", type(list(per_person_accuracy.items())))\n",
    "for item in list(per_person_accuracy.items()):\n",
    "    print(\"Item:\", item, \"Type:\", type(item))\n",
    "    for element in item:\n",
    "        print(\" - Element:\", element, \"Type:\", type(element))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "011dd2ca-dd72-4c95-a444-a59cd670a127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: /Users/viktoriiadrozdovska/face_rec_images/test/Jim_Carrey/Jim_Carrey_cropped.jpg\n",
      "Detected: Jim_Carrey\n",
      "Actual: Jim_Carrey\n",
      "Recognition Status: Correct\n",
      "\n",
      "Annotated image saved to '/Users/viktoriiadrozdovska/face_rec_images/test_annotated/annotated_Jim_Carrey_cropped.jpg'.\n",
      "\n",
      "Processing image: /Users/viktoriiadrozdovska/face_rec_images/test/Viktoriia Drozdovska/Viktoriia_Drozdovska_cropped.jpg\n",
      "Detected: Viktoriia Drozdovska\n",
      "Actual: Viktoriia Drozdovska\n",
      "Recognition Status: Correct\n",
      "\n",
      "Annotated image saved to '/Users/viktoriiadrozdovska/face_rec_images/test_annotated/annotated_Viktoriia_Drozdovska_cropped.jpg'.\n",
      "\n",
      "Processing image: /Users/viktoriiadrozdovska/face_rec_images/test/Kim_Kardashian/Kim_Kardashian_cropped.jpg\n",
      "Detected: Kim_Kardashian\n",
      "Actual: Kim_Kardashian\n",
      "Recognition Status: Correct\n",
      "\n",
      "Annotated image saved to '/Users/viktoriiadrozdovska/face_rec_images/test_annotated/annotated_Kim_Kardashian_cropped.jpg'.\n",
      "\n",
      "\n",
      "--- Overall Accuracy ---\n",
      "Total Faces Processed: 3\n",
      "Correct Recognitions: 3\n",
      "Accuracy: 100.00%\n",
      "\n",
      "--- Per-Person Accuracy ---\n",
      "Jim_Carrey: 100.00% (1/1)\n",
      "Viktoriia Drozdovska: 100.00% (1/1)\n",
      "Kim_Kardashian: 100.00% (1/1)\n",
      "\n",
      "Per-Person Accuracy Data: {'Jim_Carrey': 100.0, 'Viktoriia Drozdovska': 100.0, 'Kim_Kardashian': 100.0}\n",
      "\n",
      "No misrecognized images.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import face_recognition\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2  # Import OpenCV\n",
    "\n",
    "# Paths\n",
    "test_dir = '/Users/viktoriiadrozdovska/face_rec_images/test'\n",
    "model_load_path = '/Users/viktoriiadrozdovska/face_rec_images/face_encodings.pkl'\n",
    "output_dir = '/Users/viktoriiadrozdovska/face_rec_images/test_annotated'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load known faces and encodings\n",
    "with open(model_load_path, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "known_face_encodings = data[\"encodings\"]\n",
    "known_face_names = data[\"names\"]\n",
    "\n",
    "# Initialize variables for accuracy calculation\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Initialize per-person tracking\n",
    "per_person_correct = defaultdict(int)\n",
    "per_person_total = defaultdict(int)\n",
    "misrecognized = []\n",
    "\n",
    "# Iterate through each person in the test directory\n",
    "for person_name in os.listdir(test_dir):\n",
    "    person_test_dir = os.path.join(test_dir, person_name)\n",
    "    if not os.path.isdir(person_test_dir):\n",
    "        print(f\"Skipping '{person_test_dir}': Not a directory.\\n\")\n",
    "        continue  # Skip if not a directory\n",
    "\n",
    "    # Iterate through each image of the person\n",
    "    for img_name in os.listdir(person_test_dir):\n",
    "        img_path = os.path.join(person_test_dir, img_name)\n",
    "        print(f\"Processing image: {img_path}\")\n",
    "\n",
    "        # Load the image using face_recognition\n",
    "        try:\n",
    "            image = face_recognition.load_image_file(img_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading '{img_path}': {e}. Skipping.\\n\")\n",
    "            continue\n",
    "\n",
    "        # Verify that 'image' is a numpy array\n",
    "        if not isinstance(image, np.ndarray):\n",
    "            print(f\"Loaded image is not a NumPy array for '{img_path}'. Skipping.\\n\")\n",
    "            continue\n",
    "\n",
    "        # Check image dimensions\n",
    "        if image.ndim != 3 or image.shape[2] != 3:\n",
    "            print(f\"Unexpected image shape {image.shape} for '{img_path}'. Skipping.\\n\")\n",
    "            continue\n",
    "\n",
    "        # Detect face locations and encodings\n",
    "        face_locations = face_recognition.face_locations(image)\n",
    "        face_encodings = face_recognition.face_encodings(image, face_locations)\n",
    "\n",
    "        # If no faces are found, skip the image\n",
    "        if len(face_encodings) == 0:\n",
    "            print(f\"No faces found in '{img_path}'. Skipping.\\n\")\n",
    "            continue\n",
    "\n",
    "        # Convert the image to BGR color (which OpenCV uses)\n",
    "        image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Iterate through each face found in the image\n",
    "        for (top, right, bottom, left), encoding in zip(face_locations, face_encodings):\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, encoding, tolerance=0.6)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            # Use the first match found\n",
    "            if True in matches:\n",
    "                first_match_index = matches.index(True)\n",
    "                name = known_face_names[first_match_index]\n",
    "\n",
    "            # Update counts\n",
    "            per_person_total[person_name] += 1\n",
    "            total += 1\n",
    "            if name == person_name:\n",
    "                correct += 1\n",
    "                per_person_correct[person_name] += 1\n",
    "            else:\n",
    "                misrecognized.append({\n",
    "                    'actual': person_name,\n",
    "                    'recognized': name,\n",
    "                    'image_path': img_path\n",
    "                })\n",
    "\n",
    "            # Print detailed per-face recognition result\n",
    "            print(f\"Detected: {name}\")\n",
    "            print(f\"Actual: {person_name}\")\n",
    "            recognition_status = \"Correct\" if name == person_name else \"Incorrect\"\n",
    "            print(f\"Recognition Status: {recognition_status}\\n\")\n",
    "\n",
    "            # Annotate the image with bounding box and label\n",
    "            # Draw a box around the face\n",
    "            cv2.rectangle(image_bgr, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "            # Prepare the label with name\n",
    "            label = name\n",
    "            # Draw a filled rectangle below the face for the label background\n",
    "            cv2.rectangle(image_bgr, (left, bottom - 35), (right, bottom), (0, 255, 0), cv2.FILLED)\n",
    "            # Choose a font and put the text\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(image_bgr, label, (left + 6, bottom - 6), font, 0.8, (255, 255, 255), 1)\n",
    "\n",
    "        # Save the annotated image\n",
    "        annotated_img_path = os.path.join(output_dir, f\"annotated_{img_name}\")\n",
    "        cv2.imwrite(annotated_img_path, image_bgr)\n",
    "        print(f\"Annotated image saved to '{annotated_img_path}'.\\n\")\n",
    "\n",
    "# Calculate overall accuracy\n",
    "if total > 0:\n",
    "    overall_accuracy = (correct / total) * 100\n",
    "    print(f\"\\n--- Overall Accuracy ---\")\n",
    "    print(f\"Total Faces Processed: {total}\")\n",
    "    print(f\"Correct Recognitions: {correct}\")\n",
    "    print(f\"Accuracy: {overall_accuracy:.2f}%\")\n",
    "else:\n",
    "    print(\"No faces were processed.\")\n",
    "\n",
    "# Calculate per-person accuracy\n",
    "print(f\"\\n--- Per-Person Accuracy ---\")\n",
    "per_person_accuracy = {}\n",
    "for person in per_person_total:\n",
    "    accuracy = (per_person_correct[person] / per_person_total[person]) * 100 if per_person_total[person] > 0 else 0\n",
    "    per_person_accuracy[person] = accuracy\n",
    "    print(f\"{person}: {accuracy:.2f}% ({per_person_correct[person]}/{per_person_total[person]})\")\n",
    "\n",
    "# Debugging: Print per_person_accuracy, persons, and accuracies\n",
    "print(f\"\\nPer-Person Accuracy Data: {per_person_accuracy}\")\n",
    "\n",
    "# Print misrecognized images details\n",
    "if misrecognized:\n",
    "    print(f\"\\n--- Misrecognized Images ---\")\n",
    "    for item in misrecognized:\n",
    "        print(f\"Image: {item['image_path']}\")\n",
    "        print(f\"Actual: {item['actual']}, Recognized: {item['recognized']}\\n\")\n",
    "else:\n",
    "    print(\"\\nNo misrecognized images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf04775-56f8-4225-8eae-085f64cfc2e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
